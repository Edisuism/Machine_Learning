{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Assignment 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Edisuism/Machine_Learning/blob/master/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y40Wnu5bCqy8",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0nu7t0NDOs7",
        "colab_type": "text"
      },
      "source": [
        "In this page, I will develop a machine learning algorithm from scratch and then test it on a sample dataset\n",
        "\n",
        "Steps involved:\n",
        "- Find sample dataset\n",
        "- Choose learner algorithm and note down input/output\n",
        "- Preprocess sample dataset to input requirements and split into test/training sets \n",
        "- code learner algorithm **(only this needs to be coded, preprocessing can use from libaries like SKlearn)**\n",
        "- train algorithm and then apply to test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwhHrbnmCys0",
        "colab_type": "text"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1b1-Y0DDH6I",
        "colab_type": "text"
      },
      "source": [
        "new text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjOWe-mpC56K",
        "colab_type": "text"
      },
      "source": [
        "# Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNgoAZ--C9lR",
        "colab_type": "text"
      },
      "source": [
        "# Methodology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByoxS30g0QrK",
        "colab_type": "text"
      },
      "source": [
        "Import data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCqWnuyEYZs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import log2 as log\n",
        "import random\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/Edisuism/Machine_Learning/master/play_tennis.csv'\n",
        "df = pd.read_csv(url)\n",
        "print (len(df))\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVHi95HI0paY",
        "colab_type": "text"
      },
      "source": [
        "Split into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCOfjN-M0omX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test_split(df, test_size):\n",
        "  test_size = round(test_size * len(df))\n",
        "  indices = df.index.tolist()\n",
        "  test_indices = random.sample(population = indices, k = test_size)\n",
        "  test_df = df.loc[test_indices]\n",
        "  train_df = df.drop(test_indices)\n",
        "  \n",
        "  return train_df, test_df\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D78itKcu29oI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df, test_df = train_test_split(df, test_size = 0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxMOPEAx4Tcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (len(train_df))\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta_q1Gyz4KJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (len(test_df))\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLONyUDzLb-J",
        "colab_type": "text"
      },
      "source": [
        "Find Entropy of Class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8tCAEBRMAdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "entropy_class = 0  \n",
        "values = train_df.play.unique()  \n",
        "for value in values:\n",
        "    fraction = df.play.value_counts()[value]/len(df.play)  \n",
        "    entropy_class += -fraction*np.log2(fraction)\n",
        "    \n",
        "print (entropy_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHVg-wXTM54z",
        "colab_type": "text"
      },
      "source": [
        "Find Entropy and Information Gain of Attributes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY6_xT_oM-Y_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attribute_E_IG(target_attribute):\n",
        "  attribute = target_attribute\n",
        "  eps = np.finfo(float).eps #In case of 0 denominator\n",
        "  target_variables = train_df.play.unique() \n",
        "  variables = train_df[attribute].unique()    \n",
        "  entropy_attribute = 0\n",
        "  for variable in variables:\n",
        "      entropy_each_feature = 0\n",
        "      for target_variable in target_variables:\n",
        "          num = len(train_df[attribute][train_df[attribute]==variable][train_df.play ==target_variable]) \n",
        "          den = len(train_df[attribute][train_df[attribute]==variable])  \n",
        "          fraction = num/(den+eps)  \n",
        "          entropy_each_feature += -fraction*log(fraction+eps) #entropy for one feature \n",
        "      fraction2 = den/len(train_df)\n",
        "      entropy_attribute += -fraction2*entropy_each_feature   #all the entropy for attribute\n",
        "  E_final = abs(entropy_attribute)\n",
        "  IG_final = entropy_class - E_final\n",
        "  return E_final, IG_final, target_attribute\n",
        "\n",
        "print (attribute_E_IG('outlook'))\n",
        "print (attribute_E_IG('temp'))\n",
        "print (attribute_E_IG('humidity'))\n",
        "print (attribute_E_IG('wind'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pc5XGKaYX6_",
        "colab_type": "text"
      },
      "source": [
        "Notes:\n",
        "Gini index = how much uncertainty there is in a node\n",
        ",Information gain = how much uncertainty is removed in a node"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi__evFcC_yR",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8y0PAD1DCLp",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTJzMM0vDE0X",
        "colab_type": "text"
      },
      "source": [
        "# Ethical"
      ]
    }
  ]
}